{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train All 6 Classification Models - Bank Marketing (UCI)\n",
    "Predict term deposit subscription. Saves models as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TARGET_COLUMN = \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching Bank Marketing dataset...\")\n",
    "data = fetch_openml(name=\"bank-marketing\", version=1, as_frame=True, parser=\"auto\")\n",
    "df = pd.concat([data.data, data.target], axis=1)\n",
    "df.columns = df.columns.astype(str)\n",
    "target_col = df.columns[-1]\n",
    "df = df.rename(columns={target_col: TARGET_COLUMN})\n",
    "df[TARGET_COLUMN] = df[TARGET_COLUMN].astype(str).str.strip().str.lower()\n",
    "feature_cols = [c for c in df.columns if c != TARGET_COLUMN]\n",
    "print(f\"Shape: {df.shape}, Features: {len(feature_cols)}\")\n",
    "print(f\"Target classes: {df[TARGET_COLUMN].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    base_dir = Path.cwd()\n",
    "output_dir = base_dir\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "transformers = []\n",
    "if numeric_cols:\n",
    "    transformers.append((\"num\", StandardScaler(), numeric_cols))\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols))\n",
    "if not transformers:\n",
    "    transformers.append((\"num\", StandardScaler(), feature_cols))\n",
    "preprocessor = ColumnTransformer(transformers, remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[feature_cols]\n",
    "y = df[TARGET_COLUMN]\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_enc)\n",
    "preprocessor.fit(x_train)\n",
    "print(f\"Train: {len(x_train)}, Test: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    return {\n",
    "        \"Logistic Regression\": Pipeline([(\"prep\", preprocessor), (\"model\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))]),\n",
    "        \"Decision Tree\": Pipeline([(\"prep\", preprocessor), (\"model\", DecisionTreeClassifier(random_state=RANDOM_STATE))]),\n",
    "        \"KNN\": Pipeline([(\"prep\", preprocessor), (\"model\", KNeighborsClassifier(n_neighbors=5))]),\n",
    "        \"Naive Bayes\": Pipeline([(\"prep\", preprocessor), (\"model\", GaussianNB())]),\n",
    "        \"Random Forest (Ensemble)\": Pipeline([(\"prep\", preprocessor), (\"model\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE))]),\n",
    "        \"XGBoost (Ensemble)\": Pipeline([(\"prep\", preprocessor), (\"model\", XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=4, objective=\"binary:logistic\", eval_metric=\"logloss\", random_state=RANDOM_STATE))]),\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    preds = model.predict(x_test)\n",
    "    try:\n",
    "        probs = model.predict_proba(x_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "    except Exception:\n",
    "        auc = 0.0\n",
    "    return {\"Accuracy\": accuracy_score(y_test, preds), \"AUC\": auc, \"Precision\": precision_score(y_test, preds, average=\"binary\", zero_division=0), \"Recall\": recall_score(y_test, preds, average=\"binary\", zero_division=0), \"F1 Score\": f1_score(y_test, preds, average=\"binary\", zero_division=0), \"MCC\": matthews_corrcoef(y_test, preds)}\n",
    "\n",
    "models = make_models()\n",
    "metrics = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(x_train, y_train)\n",
    "    metrics[name] = evaluate_model(model, x_test, y_test)\n",
    "    safe_name = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    with open(output_dir / f\"{safe_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "test_df = x_test.copy()\n",
    "test_df[TARGET_COLUMN] = le.inverse_transform(y_test)\n",
    "test_df.to_csv(output_dir / \"test_data.csv\", index=False)\n",
    "with open(output_dir / \"feature_names.json\", \"w\") as f:\n",
    "    json.dump({\"features\": feature_cols, \"target\": TARGET_COLUMN, \"classes\": le.classes_.tolist()}, f, indent=2)\n",
    "with open(output_dir / \"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "print(\"Saved to:\", output_dir)\n",
    "pd.DataFrame(metrics).T.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
